{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189b6163-5c42-40f2-9004-a45f99c3842a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchmetrics.functional import accuracy\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Sampler\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from collections import OrderedDict\n",
    "from typing import Sized, Iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5c8129-3ff1-4885-8a15-135fba0603a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lenet5(nn.Module):\n",
    "    \n",
    "    \n",
    "    def __init__(self)->None:\n",
    "        super(Lenet5, self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Sequential(OrderedDict([\n",
    "            ('conv1', nn.Conv2d(3, 6, kernel_size=(5, 5))),\n",
    "            ('relu1', nn.ReLU()),\n",
    "            ('pool1', nn.MaxPool2d(kernel_size=(2, 2), stride=2))\n",
    "        ]))\n",
    "        \n",
    "        self.layer2 = nn.Sequential(OrderedDict([\n",
    "            ('conv2', nn.Conv2d(6, 16, kernel_size=(5, 5))),\n",
    "            ('relu2', nn.ReLU()),\n",
    "            ('pool2', nn.MaxPool2d(kernel_size=(2, 2), stride=2))\n",
    "        ]))\n",
    "        \n",
    "        self.fc1 = nn.Sequential(OrderedDict([\n",
    "            ('f4', nn.Linear(400, 84)),\n",
    "            ('relu4', nn.ReLU())\n",
    "        ]))\n",
    "        \n",
    "        self.fc2 = nn.Sequential(OrderedDict([\n",
    "            ('f5', nn.Linear(84, 10)),\n",
    "        ]))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9938fe57-3b21-434f-a13b-95ec29cdb26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b79574-fb44-4f91-8c21-07f47a10d715",
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate = Lenet5()\n",
    "surrogate.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42744789-cf58-48d1-86e7-2889d909d346",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchReorderSampler(Sampler[int]):\n",
    "\n",
    "    def __init__(self, data_source: Sized,  surrogate= surrogate, batch_size=32) -> None:\n",
    "        self.data_source = data_source\n",
    "        \n",
    "        self.surrogate = surrogate\n",
    "\n",
    "        self.epoch1 = True\n",
    "        self.batchOrder = torch.randperm((len(data_source)//batch_size)*batch_size)\n",
    "        self.batchOrder = self.batchOrder.reshape(-1, batch_size)\n",
    "        \n",
    "        data = [self.data_source.__getitem__(j) for j in self.batchOrder.view(-1)]\n",
    "        data, labels = zip(*data)\n",
    "        self.data = torch.stack(data).to(device)\n",
    "        self.labels = torch.LongTensor(labels).to(device)\n",
    "     \n",
    "    def __getSurrogateloss__(self, batch):\n",
    "        \n",
    "        \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            loss = F.nll_loss(self.surrogate(self.data[batch]) ,self.labels[batch])\n",
    "        \n",
    "        return loss.cpu().item()\n",
    "    \n",
    "    \n",
    "    def __iter__(self) -> Iterator[int]:\n",
    "        \n",
    "        \n",
    "        if self.epoch1 == True:\n",
    "            print('Waiting to Attack')\n",
    "            for i in range(self.batchOrder.shape[0]):\n",
    "                yield iter(self.batchOrder[i])\n",
    "            \n",
    "            self.epoch1 = False\n",
    "            \n",
    "        else:\n",
    "            print('Attacking')\n",
    "            losses = torch.Tensor([self.__getSurrogateloss__(batch) for batch in self.batchOrder])\n",
    "            \n",
    "            for i in torch.argsort(losses):\n",
    "                yield iter(self.batchOrder[i])\n",
    "        \n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.batchOrder.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c569d542-5739-4294-af85-eb33f4f51277",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchShuffleSampler(Sampler[int]):\n",
    "\n",
    "    def __init__(self, data_source: Sized,  surrogate= surrogate, batch_size=32) -> None:\n",
    "        self.data_source = data_source\n",
    "        \n",
    "        self.surrogate = surrogate\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.epoch1 = True\n",
    "        self.batchOrder = torch.randperm((len(data_source)//batch_size)*batch_size)\n",
    "        \n",
    "        data = [self.data_source.__getitem__(j) for j in self.batchOrder.view(-1)]\n",
    "        data, labels = zip(*data)\n",
    "        self.data = torch.stack(data).to(device)\n",
    "        self.labels = torch.LongTensor(labels).to(device)\n",
    "     \n",
    "    def __getSurrogateloss__(self, batch):\n",
    "        \n",
    "        \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            loss = F.nll_loss(self.surrogate(self.data[batch:batch+1]) ,self.labels[batch:batch+1])\n",
    "        \n",
    "        return loss.cpu().item()\n",
    "    \n",
    "    \n",
    "    def __iter__(self) -> Iterator[int]:\n",
    "        \n",
    "        \n",
    "        if self.epoch1 == True:\n",
    "            print('Waiting to Attack')\n",
    "            \n",
    "            for i in self.batchOrder.view(-1, self.batch_size):\n",
    "                yield iter(i)\n",
    "            \n",
    "            self.epoch1 = False\n",
    "            \n",
    "        else:\n",
    "            print('Attacking')\n",
    "            losses = torch.Tensor([self.__getSurrogateloss__(batch) for batch in self.batchOrder])\n",
    "            \n",
    "            for i in self.batchOrder[torch.argsort(losses)].view(-1, self.batch_size):\n",
    "                yield iter(i)\n",
    "        \n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.batchOrder.view(-1, self.batch_size).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767df0ce-63da-4ed4-843a-478a030bb4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "train_transform = transforms.Compose(\n",
    "    [\n",
    "     torchvision.transforms.RandomCrop(32, padding=4),\n",
    "#      torchvision.transforms.Resize(),\n",
    "     torchvision.transforms.RandomHorizontalFlip(),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=train_transform)\n",
    "\n",
    "# trainloader = torch.utils.data.DataLoader(trainset, num_workers=16, batch_sampler=BatchReorderSampler(trainset))\n",
    "# trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "#                                          num_workers=16, batch_sampler=BatchReorderSampler(trainset))#, shuffle=True\n",
    "trainloader = torch.utils.data.DataLoader(trainset, num_workers=16, batch_sampler=BatchShuffleSampler(trainset))\n",
    "\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=test_transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=16)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f190256-5aa1-4fcd-a786-b0b86d2b7b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet18CIFAR10():\n",
    "    model = torchvision.models.resnet18(pretrained=False, num_classes=10)\n",
    "    model.conv1 = nn.Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "    model.maxpool = nn.Identity()\n",
    "    \n",
    "    return model\n",
    "\n",
    "class BoilerPlate(pl.LightningModule):\n",
    "    def __init__(self, train_l, val_l, surrogate) -> None:\n",
    "        super(BoilerPlate, self).__init__()\n",
    "\n",
    "        self.train_l = train_l\n",
    "        self.val_l = val_l\n",
    "        \n",
    "        self.model = resnet18CIFAR10()\n",
    "        \n",
    "        \n",
    "        self.surrogate = surrogate\n",
    "        self.surrogate_optim = Adam([p for p in self.surrogate.parameters() if p.requires_grad],lr=0.1)\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.model(x)\n",
    "        \n",
    "        return F.log_softmax(out, dim=1)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        \n",
    "        loss = F.nll_loss(logits, y)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        \n",
    "        \n",
    "        self.surrogate_optim.zero_grad()\n",
    "        surrogate_logits = self.surrogate(x)\n",
    "        surrogateloss = F.nll_loss(surrogate_logits, y)\n",
    "        surrogateloss.backward()\n",
    "        self.surrogate_optim.step()\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def evaluate(self, batch, stage=None):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = accuracy(preds, y)\n",
    "\n",
    "        if stage:\n",
    "            self.log(f\"{stage}_loss\", loss, prog_bar=True)\n",
    "            self.log(f\"{stage}_acc\", acc, prog_bar=True)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        self.evaluate(batch, \"val\")\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return Adam([p for p in self.model.parameters() if p.requires_grad], lr=0.1)\n",
    "\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return self.train_l\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return self.val_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9512b6-ef39-47fc-b9d2-29c1e8165adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BoilerPlate(trainloader, testloader, surrogate)\n",
    "trainer = pl.Trainer(\n",
    "    progress_bar_refresh_rate=10,\n",
    "    max_epochs=100,\n",
    "    gpus=1,\n",
    "    logger=pl.loggers.TensorBoardLogger(\"lightning_logs/\", name=\"test\"),\n",
    ")\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ae1058-f93a-4bc8-8623-c7073575bfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=test_transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=16)\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "preds, labels = [], []\n",
    "for batch in testloader:\n",
    "    x, y = batch\n",
    "    x = x.to(device)\n",
    "    logits = model(x)\n",
    "    y_pred = torch.argmax(logits, dim=1)\n",
    "    \n",
    "    preds.append(y_pred.cpu().numpy())\n",
    "    labels.append(y.cpu().numpy())\n",
    "\n",
    "preds = np.concatenate(preds)\n",
    "labels = np.concatenate(labels)\n",
    "print(classification_report(labels, preds, target_names=classes))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4da4b38d-be78-485b-bb3d-2d6d6c1994df",
   "metadata": {},
   "source": [
    "Reorder:\n",
    "Files already downloaded and verified\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       plane       0.90      0.89      0.89      1000\n",
    "         car       0.97      0.92      0.94      1000\n",
    "        bird       0.73      0.83      0.78      1000\n",
    "         cat       0.75      0.75      0.75      1000\n",
    "        deer       0.87      0.84      0.86      1000\n",
    "         dog       0.80      0.80      0.80      1000\n",
    "        frog       0.95      0.89      0.92      1000\n",
    "       horse       0.92      0.92      0.92      1000\n",
    "        ship       0.92      0.93      0.92      1000\n",
    "       truck       0.92      0.93      0.93      1000\n",
    "\n",
    "    accuracy                           0.87     10000\n",
    "   macro avg       0.87      0.87      0.87     10000\n",
    "weighted avg       0.87      0.87      0.87     10000\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8a756baa-bb4e-4c00-9035-1b3430dc1d13",
   "metadata": {},
   "source": [
    "Reshuffle:\n",
    "Files already downloaded and verified\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       plane       0.78      0.87      0.82      1000\n",
    "         car       0.88      0.94      0.91      1000\n",
    "        bird       0.73      0.82      0.77      1000\n",
    "         cat       0.82      0.53      0.64      1000\n",
    "        deer       0.76      0.90      0.82      1000\n",
    "         dog       0.72      0.78      0.75      1000\n",
    "        frog       0.86      0.89      0.87      1000\n",
    "       horse       0.89      0.87      0.88      1000\n",
    "        ship       0.95      0.85      0.90      1000\n",
    "       truck       0.96      0.82      0.88      1000\n",
    "\n",
    "    accuracy                           0.83     10000\n",
    "   macro avg       0.83      0.83      0.83     10000\n",
    "weighted avg       0.83      0.83      0.83     10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677f8137-539f-4bca-ac30-45e11039efbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
